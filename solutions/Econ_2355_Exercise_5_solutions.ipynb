{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ECON 2355 Implementation Exercise 5: Contrastive Learning\n",
        "\n",
        "This exercise introduces Contrastive Learning, focusing on supervised contrastive learning. Many social science applications of Deep Learning naturally present as a contrastive learning problem, including OCR, topic classification, passage retrieval, etc. The exercise has four main parts:\n",
        "\n",
        "1. Introduction to Pytorch Loss functions.\n",
        "2. Implementing Supervised Contrastive Loss.\n",
        "3. Training a character recognition model with SupCon Loss.\n",
        "\n",
        "TOM TODO: Add notes for GPU limitations\n",
        "\n",
        "### Notes on the class's implementation exercises in general:\n",
        "\n",
        " - These exercises are still being finalized! If you encounter problems please don't hesitate to reach out: tom_bryan@fas.harvard.edu\n",
        "\n",
        " - You are welcome to download these notebooks and complete them on your local machine, or work on them in colab. If you are hoping to run things on your local machine you will likely want to set up an [Anaconda](https://www.anaconda.com/products/distribution) python environment and run notebooks from either [VS Code](https://code.visualstudio.com/download) or [Jupyter Lab](https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html). For your future Deep Learning-oriented endevours, knowing how to set up an environment to run the frameworks and libraries discussed here will likely be important, so it might not be a bad idea to try setting things up locally. On the other hand, working in colab is nice for reproducibility purposes--anyone can run and/or debug your code without problems.\n",
        "\n",
        " - Exercises in this class use [PyTorch](https://pytorch.org/get-started/locally/), the [dominant](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/) research deep learning python framework. If you have a _compelling_ reason why you wish to become more familiar with another framework, like Tensorflow, reach out and we _may_ be able to accomodate that.\n",
        "\n",
        " - To submit the assignements, please save the exercise as a `.ipynb` file named `ECON_2355_Exercise_{n}_{firstname}_{lastname}.ipynb` and submit to the appropriate place in Canvas.  \n",
        "\n",
        " - These exercises are graded as complete/incomplete. _Complete_ is defined as showing effort to complete at all of the steps.\n"
      ],
      "metadata": {
        "id": "gPpNAUoDgwZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Pytorch Loss Functions Example\n",
        "\n",
        "Pytorch supports a wide range of loss functions. Given a set of model outputs and some labels, they provide a measurement of the model's performance. In this first exercise, you will implement a commonly used loss function, Cross Entropy Loss.\n",
        "\n",
        "As we've seen in these exercises, [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) is commonly used for classification problems. For each labeled data instance, it accepts a set of probabilities, one per class, and a true class label. It then computes:\n",
        "\n",
        "$$L_i = -log\\frac{exp(x_{i, c'})}{\\sum_{c=1}^{C} exp(x_{i, c})} $$\n",
        "\n",
        "Where $c'$ is the correct, $C$ is the set of all possible classes, $i \\in \\{1, ..., N\\}$ with $N = \\text{batch size}$, and $x_{i, c}$ is the predicted probability for each class for instance $i$.\n",
        "\n",
        "In pytorch, loss functions behave much like any other module. They inherit the `torch.nn.module` class and need to implement the `forward` method. For a loss function, `forward` computes the loss given some predictions.\n",
        "\n",
        "Pytorch has two options for pooling loss across elements in a batch: averaging and summing. The default, which we will use here, is to average the loss from each element in a batch.\n",
        "\n",
        "As a practice, we'll start by implementing the Cross Entropy Loss function.\n",
        "\n",
        "- **TODO:** Finish implementing CrossEntropyLoss, following the method signature and comments' advice.\n",
        "\n",
        "_Hint_: In pytorch, selecting sets of values at specific indices is done by indexing at matched `tuples`. For example:\n",
        "\n",
        "```[python]\n",
        "[1]: ex_tensor = torch.Tensor([[1, 2, 3],\n",
        "                               [4, 5, 6],\n",
        "                               [7, 8, 9]])\n",
        "\n",
        "[2]: ex_tensor[1, 1]\n",
        "\n",
        ">> torch.Tensor([5])\n",
        "\n",
        "[3]: ex_tensor[(0, 2, 1), (0, 1, 0)]\n",
        "\n",
        ">> torch.Tensor([1, 8, 4])\n",
        "\n",
        "```\n",
        "\n",
        "Note that this requires `tuple` inputs. `ex_tensor[torch.Tensor([0, 1, 2])]` will cause an error."
      ],
      "metadata": {
        "id": "NJllh8SPhdTh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYoUh2SaA0uA"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement CrossEntropyLoss\n",
        "class CrossEntropyLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CrossEntropyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred : torch.Tensor, y_true : torch.Tensor):\n",
        "      '''\n",
        "      Computes the Cross Entropy Loss for a set of predictions and true labels\n",
        "\n",
        "      Args:\n",
        "        y_pred (torch.Tensor): shape (batch_size, num_classes) Predictions for each class\n",
        "        y_true (torch.Tensor): shape (batch_size,) Labels for each instances\n",
        "\n",
        "      Returns:\n",
        "        torch.Tensor: shape (1,) Loss averaged across the batch\n",
        "      '''\n",
        "\n",
        "      # Take the exponential of all predictions\n",
        "      exp_preds = torch.exp(y_pred)\n",
        "\n",
        "      # Calculate the summed exponentials for the denominators of the Cross Entropy Loss calculation\n",
        "      denominators = torch.sum(exp_preds, dim=1)\n",
        "\n",
        "      # Find the exponentiated values predicted for each true label\n",
        "      corr_preds = exp_preds[range(y_pred.size()[0]), tuple(y_true)]\n",
        "\n",
        "      # Divide element-wise by the denominators\n",
        "      inner = corr_preds / denominators\n",
        "\n",
        "      # Take the negative log and average across the batch\n",
        "      return -1 * torch.sum(torch.log(inner)) / y_pred.size(0)\n"
      ],
      "metadata": {
        "id": "q3xSgQ_fXgvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make sure your implementation is correct, we can verify by comparing with pytorch's implementation. Run the following cell and ensure that both loss functions produce the same value:"
      ],
      "metadata": {
        "id": "Auc9pwmASvWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchCrossEntropyLoss = torch.nn.CrossEntropyLoss()\n",
        "yourCrossEntropyLoss = CrossEntropyLoss()\n",
        "\n",
        "test_preds = torch.nn.Softmax(dim=1)(torch.randn(10, 5))\n",
        "test_labels = torch.randint(5, (10,))\n",
        "\n",
        "print(torchCrossEntropyLoss(test_preds, test_labels))\n",
        "print(yourCrossEntropyLoss(test_preds, test_labels))"
      ],
      "metadata": {
        "id": "yiojwuA7Y-p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Supervised Contrastive Loss\n",
        "\n",
        "Contrastive loss functions train models to improve their embeddings so that similar data instances have similar embeddings. Supervised Contrastive Loss (SupCon Loss) maxminizes similarity between embeddings of the same class, and minimizes similarity between embeddings of different classes.\n",
        "\n",
        "SupCon Loss's objective function is:\n",
        "\n",
        "$$L = \\sum_{i \\in I}L_i = \\sum_{i \\in I}\\frac{-1}{|P(i)|}\\sum_{p \\in P(i)}\\text{log} \\frac{\\text{exp}(dist(z_i, z_p) / \\tau)}{\\sum_{a \\in \\{I / i\\}}\\text{exp}(dist(z_i, z_a) / \\tau)} $$\n",
        "\n",
        "Where:\n",
        "- $I$ is the set of elements in a batch\n",
        "- $P(i)$ is all elements in a batch of the same class as element $i$ (_not including $i$ itself_)\n",
        "- $z_i$ is the model's embedding for element $i$\n",
        "- $\\tau$ is a temperature parameter. Pytorch's default is 0.1.\n",
        "- $\\text{dist}(z_i, z_j)$ is some distance measure between two embeddings, such that $exp(\\text{dist}(z_i, z_i)) = 0$. Most implementations use _cosine similarity_, which is the dot product between two normalized vectors.\n",
        "\n",
        "There are many similarities between Cross Entropy Loss and Sup Con Loss--it's easy to think of SupCon loss as a extension of Cross Entropy Loss to contrastive learning.\n",
        "\n",
        "In this next section, you will create your own implementation of Supervised Contrastive Loss. The structure is very similar to the earlier Cross Entropy loss function, but a bit more complicated.\n",
        "\n",
        "Given:\n",
        "- A set of `embeddings`, a normalized $(B \\times D)$ dimensional tensor ($B$ = batch size, $D$ = dimensionality). _Normalized_ means that $x \\cdot x = 1$ for all embeddings.\n",
        "- A set of `labels`, a $B$ dimensional tensor with integer values.\n",
        "- A value for the `temperature` parameter.\n",
        "\n",
        "Your `forward` function should compute the value specified by $L$ above, _with one exception_. Instead of providing $L$ as shown, average the loss by dividing by the batch size."
      ],
      "metadata": {
        "id": "www-4kWvhj9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-metric-learning"
      ],
      "metadata": {
        "id": "i5nR6eKBbpi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_metric_learning import losses\n",
        "import torch"
      ],
      "metadata": {
        "id": "Jrd5x3JNjUS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement mySupConLoss, following the suggestions as needed\n",
        "\n",
        "class mySupConLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mySupConLoss, self).__init__()\n",
        "\n",
        "    def forward(self, embeddings, labels, temp = 0.1):\n",
        "        # Compute all pairwise dot products between embeddings\n",
        "        all_dot_products = torch.matmul(embeddings, embeddings.T)\n",
        "\n",
        "        # Take the exponent of all vectors, dividing by the temperature first\n",
        "        all_dot_products = torch.exp(all_dot_products / temp)\n",
        "\n",
        "        # Create the denominator values, making sure to exclude the ith tensor from each\n",
        "        # Tip: for each ith vector, the value value will be the same, so you can do this as a subtraction\n",
        "        denominator_sums = torch.sum(all_dot_products, dim=1) - torch.exp(torch.tensor(1) / temp)\n",
        "\n",
        "        # Divide all the dot products by the appropriate denominator\n",
        "        all_dot_products = all_dot_products / denominator_sums\n",
        "\n",
        "        # Create a mask that indicates whether two embeddings are in the same category, and set values\n",
        "        # whre they are not to 1, so they get zeroed by the log operation\n",
        "        matched_mask = (labels.unsqueeze(1) == labels.unsqueeze(0)).fill_diagonal_(False)\n",
        "        all_dot_products[matched_mask == False] = 1\n",
        "\n",
        "        # Get the sum of logs of the quotients\n",
        "        numerator_sums = torch.sum(torch.log(all_dot_products), dim = 1)\n",
        "\n",
        "        # Get the group sizes, but avoiding divide-by-zero errors by taking the max with 1\n",
        "        group_sizes = torch.maximum(torch.sum(matched_mask, dim=0), torch.tensor(1))\n",
        "\n",
        "        # Divide by group sizes and return the negative average of those values\n",
        "        return -1 * torch.sum(numerator_sums / group_sizes) / embeddings.size()[0]"
      ],
      "metadata": {
        "id": "wVh6NIN7ktZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following cells to test your function. Each creates batches of normalized tensors with labels and slightly different properties, then applies the various losses. If your function produces the same results as Pytorch's you're doing great!  "
      ],
      "metadata": {
        "id": "VCYT50W2vZ2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1: Perturbed vectors\n",
        "\n",
        "base = torch.zeros(200, 256)\n",
        "for i in range(100):\n",
        "  v = torch.randn(1, 256)\n",
        "  base[i] = v\n",
        "  base[i+100] = v + torch.randn(1, 256) * 0.01\n",
        "\n",
        "test_embeddings = torch.nn.functional.normalize(base)\n",
        "test_labels = torch.cat((torch.arange(100), torch.arange(100)))"
      ],
      "metadata": {
        "id": "TRVgLgtdZxaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supcon = mySupConLoss()\n",
        "myloss = supcon(test_embeddings, test_labels)\n",
        "\n",
        "loss_fn = losses.SupConLoss()\n",
        "ptmlloss = loss_fn(test_embeddings, test_labels)\n",
        "print('Your SupCon Loss ', myloss)\n",
        "print('Pytorch\\'s Supcon Loss ', ptmlloss)"
      ],
      "metadata": {
        "id": "qP9owUBkZ0CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2: Identical vectors\n",
        "\n",
        "base = torch.zeros(200, 256)\n",
        "labels = torch.zeros(200)\n",
        "\n",
        "for i in range(0, 200, 2):\n",
        "  v = torch.randn(1, 256)\n",
        "  base[i] = v\n",
        "  base[i+1] = v\n",
        "  labels[i] = i / 2\n",
        "  labels[i+1] = i / 2\n",
        "\n",
        "test_embeddings = torch.nn.functional.normalize(base)\n",
        "test_labels = labels"
      ],
      "metadata": {
        "id": "Nudfs_9oZEOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myloss = supcon(test_embeddings, test_labels)\n",
        "print(myloss)\n",
        "ptmlloss = loss_fn(test_embeddings, test_labels)\n",
        "print(ptmlloss)"
      ],
      "metadata": {
        "id": "2HWGTkwO7VWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Contrastively Training a Character Recognizer\n",
        "\n",
        "This section of the exercise applies Contrastive Training to its most common application: vision data. In particular, you will train a model to recognize images of english characters.\n",
        "\n",
        "We will use a dataset of historical Newspaper text. Run the folloiwng cells to download and unpack the dataset:"
      ],
      "metadata": {
        "id": "6yowSLqwbiaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Import"
      ],
      "metadata": {
        "id": "Vvd0wwTlk-fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "REPO_ID = 'dell-research-harvard/AmericanStoriesTraining'\n",
        "FILENAME = 'locca_char_crops.zip'\n",
        "\n",
        "hf_hub_download(REPO_ID, FILENAME, repo_type=\"dataset\", local_dir = '/content/', force_download = True)"
      ],
      "metadata": {
        "id": "1BMTZSXj7ecc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q locca_char_crops.zip"
      ],
      "metadata": {
        "id": "hM2mQHZydYpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two packages are crucial for our model training: `timm`, which will supply the model backbone, and `faiss`, which will perform fast vector comparisons. The following cells install them and provide some key imports"
      ],
      "metadata": {
        "id": "v4B-urtZyiJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install faiss_cpu"
      ],
      "metadata": {
        "id": "Pfbe85GlrPv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms as T\n",
        "import timm\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "import torchvision\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as nn_f\n",
        "import torchvision.transforms.functional as F\n",
        "from tqdm import tqdm\n",
        "import faiss\n",
        "from pytorch_metric_learning.samplers import MPerClassSampler"
      ],
      "metadata": {
        "id": "U3jEAznib7sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two kinds of images in the dataset. Some character images are cropped from newspaper scans, and others are renders of types characters. The following cells show examples of each type of data:"
      ],
      "metadata": {
        "id": "INa-NoIWlQV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_folder = str(ord('a'))\n",
        "a_images = os.listdir(os.path.join('locca', a_folder))\n",
        "paired_a_images = [os.path.join('locca', a_folder, a_img) for a_img in a_images if 'PAIRED' in a_img]\n",
        "rendered_a_images = [os.path.join('locca', a_folder, a_img) for a_img in a_images if 'PAIRED' not in a_img]"
      ],
      "metadata": {
        "id": "yXZ4hvCUbs0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
        "\n",
        "for i in range(4):\n",
        "    axs[i].imshow(plt.imread(paired_a_images[i + 1]))\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aNinm7vleOrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
        "\n",
        "for i in range(4):\n",
        "    axs[i].imshow(plt.imread(rendered_a_images[i + 1]))\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XaViBvNJhJF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create our vision encoder model. For this exercise, we will use the very lightweight MobileNetv3. For a more formal project, where accuracy is more crucial, a larger vision encoder will be more desireable.\n",
        "\n",
        "This cell initializes a initial vision encoder:"
      ],
      "metadata": {
        "id": "CEMQNQRoCFfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('mobilenetv3_small_050', num_classes = 0, pretrained=True)"
      ],
      "metadata": {
        "id": "wkilB17JYH4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cells handle some smaller, but crucial details in setting up the data for training. Make sure to run them, and follow comments to see what each is doing:"
      ],
      "metadata": {
        "id": "pjNU2zpLCb5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Creating SquarePad, a custom transform that takes images and pads them to a square\n",
        "Crucial for applying before we resize images, so that the aspect ratio is preserved\n",
        "'''\n",
        "class SquarePad:\n",
        "  def __call__(self, image):\n",
        "    w, h = image.size\n",
        "    max_wh = max(w, h)\n",
        "    p_side, p_top = abs(w - max_wh) // 2, abs(h - max_wh) // 2\n",
        "    return F.pad(image, (p_side, p_top, p_side, p_top), fill=255)\n",
        "\n",
        "transform = T.Compose([\n",
        "    SquarePad(),\n",
        "    T.Resize((224, 224), antialias = True),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n",
        "])"
      ],
      "metadata": {
        "id": "V5NqZjQM2atM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Creating the dataset using a torchvision ImageFolder. See previous exercises for a\n",
        "reminder on how these are structured.\n",
        "'''\n",
        "full_dataset = torchvision.datasets.ImageFolder(\n",
        "    root='locca',\n",
        "    transform=transform,\n",
        ")"
      ],
      "metadata": {
        "id": "m2XJhmqw3pQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "These lines create a dictionary that maps from the default created labels (classes 0-N,\n",
        "which don't correspond to the numerical image folder names) to the true character labels\n",
        "'''\n",
        "label_char_mapping = {}\n",
        "for f_name, label in full_dataset.imgs:\n",
        "  if f_name.split('/')[-1].startswith('0x') and label not in label_char_mapping.keys():\n",
        "    label_char_mapping[label] = chr(int(f_name.split('/')[-1].split('_')[0], base=16))"
      ],
      "metadata": {
        "id": "vhR7-9AUWxQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idxs, val_idxs, test_idxs = [], [], []\n",
        "TRAIN_P, VAL_P, TEST_P = 0.8, 0.1, 0.1\n",
        "\n",
        "# We want the train set to have all the rendered images, and 80% of the actual samples.\n",
        "# The remaining 20% of real images are divided between the validation and test sets\n",
        "for i, (f_name, _) in enumerate(full_dataset.imgs):\n",
        "  if 'PAIRED' not in f_name:\n",
        "    train_idxs.append(i)\n",
        "  else:\n",
        "    r = random.random()\n",
        "    if r < TRAIN_P:\n",
        "      train_idxs.append(i)\n",
        "    elif r < TRAIN_P + VAL_P:\n",
        "      val_idxs.append(i)\n",
        "    else:\n",
        "      test_idxs.append(i)\n",
        "\n",
        "print(len(train_idxs), len(val_idxs), len(test_idxs))"
      ],
      "metadata": {
        "id": "3S6uRa7JTXMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Using selected indices to partition the dataset into train, test, and validation sets.\n",
        "Each Subset functions as its own dataset.\n",
        "'''\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(full_dataset, train_idxs)\n",
        "val_dataset = torch.utils.data.Subset(full_dataset, val_idxs)\n",
        "test_dataset = torch.utils.data.Subset(full_dataset, test_idxs)\n",
        "\n",
        "train_labels = [full_dataset.targets[i] for i in train_idxs]\n",
        "val_labels = [full_dataset.targets[i] for i in val_idxs]\n",
        "test_labels = [full_dataset.targets[i] for i in test_idxs]"
      ],
      "metadata": {
        "id": "0Z_4ax1MUVZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've completed setup, we can see some samples of the final input data. Note that the fullowing examples are padded to a square,\n",
        "resized to a standard 224x224 size, and normalized to create the representations below.\n",
        "\n",
        "Training examples like these are exactly what the model will see."
      ],
      "metadata": {
        "id": "BZ4bYY7eDOeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
        "\n",
        "for i in range(4):\n",
        "    dataset_idx = i * 1000\n",
        "    axs[i].imshow(F.to_pil_image(train_dataset[dataset_idx][0]))\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(label_char_mapping[train_dataset[dataset_idx][1]])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0z21bwl3uSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised Contrastive training requires batches with specific properties. In particular, batches must include groups of positives for each item in each batch. The following sampler will modify typical `DataLoader` behavior to create batches that contain `batch_size / m` groups from random classes."
      ],
      "metadata": {
        "id": "tlk6a3qYDhcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sampler = MPerClassSampler(\n",
        "    train_labels,\n",
        "    m=4,\n",
        "    length_before_new_iter=len(train_dataset),\n",
        ")"
      ],
      "metadata": {
        "id": "FF0iCSS_UMUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These `DataLoader` objects will be used for training and testing. Note that we only use the special sampler initialized above for the train dataset. Validation and test can provide batches with any mix of classes.   "
      ],
      "metadata": {
        "id": "zqpK65cCJHkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    sampler=train_sampler,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        ")"
      ],
      "metadata": {
        "id": "0d_NIgUQePI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions in a contrastive setting requires a template, or \"anchor\" set of examples. In this case, we use examples from the 'NotoSerif' typeface, which are very standard-looking characters. The following cells (1) show examples of this font and (2) create a dataset containing each example."
      ],
      "metadata": {
        "id": "IEgCSIbKJcqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
        "\n",
        "for i, folder in enumerate(os.listdir('locca')[:4]):\n",
        "  for f_name in os.listdir(os.path.join('locca', folder)):\n",
        "    if 'NotoSerif' in f_name:\n",
        "      axs[i].imshow(plt.imread(os.path.join('locca', folder, f_name)))\n",
        "      axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BnL7Fuy7t2DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_idxs = []\n",
        "for i, (f_name, _) in enumerate(full_dataset.imgs):\n",
        "  if 'NotoSerif' in f_name:\n",
        "    anchor_idxs.append(i)\n",
        "\n",
        "anchor_dataset = torch.utils.data.Subset(full_dataset, anchor_idxs)\n",
        "anchor_loader = torch.utils.data.DataLoader(\n",
        "    anchor_dataset,\n",
        "    batch_size=16\n",
        ")\n",
        "print(len(anchor_dataset))"
      ],
      "metadata": {
        "id": "SoJxj6AIfNVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**\n",
        "\n",
        "Now we've arrived at training the model. There are a few important sections for you to fill in of the main training and evaluation loop:\n",
        "\n",
        "1. **Training steps**: Add standard functions for pytorch training. Make sure to include zeroing the optimizer, passing data through the model, _normalizing the outputs_ (new for this problem because of the different loss funciton), computing the loss, backpropagating the gradients, and stepping the optimizer.\n",
        "\n",
        "2. **Computing Reference Embeddings**: For each batch in the anchor dataset, pass the data through the model, normalize the outputs, and add the embeddings to the `faiss.IndexFlatL2` that is provided as `ref_index`. This is done by simply calling `ref_index.add` on the normalized embeddings.\n",
        "\n",
        "3. **Evaluating the model**: For each batch of the validation dataset, pass the data through the model, normalize the embeddings, and look up the nearest neighbor of each embedding in the `ref_index` using `ref_index.search()`. Then compute the number of correct predictions the model made and add it to `num_correct`."
      ],
      "metadata": {
        "id": "kmpncYSMKU2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## These initial lines set up everything you will need to train the model\n",
        "torch.manual_seed(0) # Reproducibility\n",
        "model = timm.create_model('mobilenetv3_small_050', num_classes = 0, pretrained=True) # Model initialized\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Set device\n",
        "model.to(device)\n",
        "model.train()\n",
        "losses = []\n",
        "num_epochs = 3\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002) # This learning rate works well for the mobilenetv3_small_050 model\n",
        "loss_func = mySupConLoss() # Using the loss function you wrote earlier.\n",
        "\n",
        "for n in range(num_epochs):\n",
        "  print(f'Training Epoch {n}')\n",
        "  model.train()\n",
        "  for _, (data, labels) in tqdm(enumerate(train_loader), total = int(len(train_dataset) / 16)):\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # TODO: Run the data through the model and compute the loss. Make sure to include:\n",
        "    # Zero the optimizer\n",
        "    # Run data through the model\n",
        "    # Normalize the outputs\n",
        "    # Compute the loss\n",
        "    # Backpropagate the gradients\n",
        "    # Step the optimizer\n",
        "    optimizer.zero_grad()\n",
        "    emb = model(data)\n",
        "    norm_emb = nn_f.normalize(emb)\n",
        "    loss = loss_func(norm_emb, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  print('\\n Creating reference embeddings')\n",
        "  ref_index = faiss.IndexFlatL2(1024)\n",
        "  for data, labels in anchor_loader:\n",
        "    # TODO: Run the data through the model and add it to the faiss index\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    emb = model(data)\n",
        "    ref_index.add(nn_f.normalize(emb).detach().cpu().numpy())\n",
        "\n",
        "  num_correct = 0\n",
        "  print('Evaluating')\n",
        "  for _, (data, labels) in tqdm(enumerate(val_loader), total = int(len(val_dataset) / 16)):\n",
        "    # TODO: Run the data through the model, find the nearest neighbor in the ref_index, and compute accuracy.\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    emb = model(data)\n",
        "    norm_emb = nn_f.normalize(emb).detach().cpu().numpy()\n",
        "    dists, indices = ref_index.search(norm_emb, 1)\n",
        "    num_correct += (indices.flatten() == labels.cpu().numpy()).sum()\n",
        "\n",
        "  print('\\n Accuracy: ', round(num_correct / len(val_dataset), 2))\n"
      ],
      "metadata": {
        "id": "vES-3YqZfn7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hard Negatives**\n",
        "\n",
        "In the above example, the model is seeing randomized batches. However, the model will benefit much more from seeing easily confusable characters in the same batch. For example, `i` and `j` look quite similar. Focusing on those comparisons should improve model performance.\n",
        "\n",
        "To set up this kind of batching, we first need to find sets of hard negatives. Here we create the `infer_hard_negatives` function to identify those sets. It find the four most likely candidates for each training example, and makes those a set.\n",
        "\n",
        "**Fill in the missing sections to finish the function**"
      ],
      "metadata": {
        "id": "rzoZOGoyNZj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_hard_negatives(model, k, anchor_loader, train_loader, device, output_file = '/content/locca_hard_negatives.txt'):\n",
        "  model.eval()\n",
        "  ref_index = faiss.IndexFlatL2(1024)\n",
        "\n",
        "  for data, labels in anchor_loader:\n",
        "    # TODO: As above, pass the anchor set through the model and add embeddings to the ref_index\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    emb = model(data)\n",
        "    ref_index.add(nn_f.normalize(emb).detach().cpu().numpy())\n",
        "\n",
        "  hard_negative_sets = []\n",
        "  for data, labels in tqdm(train_loader, total = int(len(train_dataset) / 16)):\n",
        "    # TODO: As with the validation set above, pass the data through the model\n",
        "    # This time, instead of identifying the nearest neighbor, find the k nearest neighbors in the ref_index\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    emb = model(data)\n",
        "    norm_emb = nn_f.normalize(emb).detach().cpu().numpy()\n",
        "    dists, indices = ref_index.search(norm_emb, k)\n",
        "\n",
        "    for i in range(indices.shape[0]):\n",
        "      hard_negative_sets.append(''.join(label_char_mapping[indices[i][j]] for j in range(k)))\n",
        "\n",
        "\n",
        "  with open(output_file, 'w') as f:\n",
        "    f.write('\\n'.join(hard_negative_sets))\n",
        "\n"
      ],
      "metadata": {
        "id": "XCY7kSs_rSlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can run the function. To make sure things are working correctly, open up the created folder in `/content/locca_hard_negatives.txt`. Make sure that the sets listed look like easily confusable characters."
      ],
      "metadata": {
        "id": "2qiupDZON_oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer_hard_negatives(model, 4, anchor_loader, train_loader, device)"
      ],
      "metadata": {
        "id": "oHfo5TpS2fsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like we needed a special `Sampler` to draw batches containing groups of `m` earlier, we also need a special sampler to draw batches of hard negatives. This is implemented below:"
      ],
      "metadata": {
        "id": "sgeV64XkJ8K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class_mapping = {v: k for k, v in label_char_mapping.items()}\n",
        "\n",
        "class HardNegativeSampler(torch.utils.data.Sampler):\n",
        "  def __init__(self, dataset, hard_negatives_path, class_mapping, batch_size = 16, m = 4, length_before_new_iter = None):\n",
        "    self.dataset = dataset\n",
        "    self.class_mapping = class_mapping\n",
        "    self.m = m\n",
        "    self.length_before_new_iter = len(self.dataset) if length_before_new_iter is None else length_before_new_iter\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    with open(hard_negatives_path, 'r') as f:\n",
        "      hard_negative_groups = f.read().split('\\n')\n",
        "\n",
        "    self.hard_negative_groups = []\n",
        "    for group in hard_negative_groups:\n",
        "      self.hard_negative_groups.append([self.class_mapping[c] for c in group])\n",
        "\n",
        "    self.indices_by_class = defaultdict(list)\n",
        "    for i, (_, label) in enumerate(self.dataset):\n",
        "      self.indices_by_class[label].append(i)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def _construct_hn_batch(self, hn_group):\n",
        "    hn_batch = []\n",
        "    for c in hn_group:\n",
        "      hn_batch.extend(random.sample(self.indices_by_class[c], self.m))\n",
        "\n",
        "    return hn_batch\n",
        "\n",
        "  def __iter__(self):\n",
        "    num_batches = self.length_before_new_iter // self.batch_size\n",
        "    idx_list = []\n",
        "\n",
        "    for _ in range(num_batches):\n",
        "      idx_list.extend(self._construct_hn_batch(random.choice(self.hard_negative_groups)))\n",
        "\n",
        "    return iter(idx_list)"
      ],
      "metadata": {
        "id": "u4G55IFQmfjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create a new train loader with the HardNegativeSampler. This cell will take a few seconds to run while the DataLoader creates hard negative batches."
      ],
      "metadata": {
        "id": "DT1fKq9sOgiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    sampler=HardNegativeSampler(train_dataset, '/content/locca_hard_negatives.txt', class_mapping, 16, 4, length_before_new_iter = len(train_dataset))\n",
        ")"
      ],
      "metadata": {
        "id": "YCCbf9mXxU76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To finish the exercise, try training the model a second time, with the hard negative sampler. Copy the code from the training cell above, and train the model for 2-5 epochs. You should see slightly higher initial results, followed by slightly poorer results after a few epochs when compared with the standard, no hard negatives training from before.\n",
        "\n",
        "This is because the model will eventually see hard negative interactions given enough batches, since there are only 91 characters in this set. In scripts with more character, like Japanese, hard negative training is much more important.\n",
        "\n",
        "There is some stochasticity, however, so no need to worry if the training behavior is slightly different than described above."
      ],
      "metadata": {
        "id": "1_6QdyZ9OpOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "for n in range(num_epochs):\n",
        "  print(f'Training Epoch {n}')\n",
        "  model.train()\n",
        "  for _, (data, labels) in tqdm(enumerate(train_loader), total = int(len(train_dataset) / 16)):\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    emb = model(data)\n",
        "    norm_emb = nn_f.normalize(emb)\n",
        "    loss = loss_func(norm_emb, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  print('\\n Creating reference embeddings')\n",
        "  ref_index = faiss.IndexFlatL2(1024)\n",
        "  for data, labels in anchor_loader:\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    emb = model(data)\n",
        "    ref_index.add(nn_f.normalize(emb).detach().cpu().numpy())\n",
        "\n",
        "  num_correct = 0\n",
        "  print('Evaluating')\n",
        "  for _, (data, labels) in tqdm(enumerate(val_loader), total = int(len(val_dataset) / 16)):\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    emb = model(data)\n",
        "    norm_emb = nn_f.normalize(emb).detach().cpu().numpy()\n",
        "    dists, indices = ref_index.search(norm_emb, 1)\n",
        "    num_correct += (indices.flatten() == labels.cpu().numpy()).sum()\n",
        "\n",
        "  print('\\n Accuracy: ', round(num_correct / len(val_dataset), 2))"
      ],
      "metadata": {
        "id": "UUwqwfG5AapV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4juF67AAhS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}